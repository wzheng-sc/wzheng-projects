{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0cc7d6f-4a11-41e9-a1c2-5cd9ddbfc06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines when running for the first time to install the required packages.  This is mostly required for local development.\n",
    "# # %pip install openai\n",
    "# %pip install google-auth\n",
    "# %pip install google-cloud-bigquery\n",
    "# %pip install google-cloud-storage\n",
    "# %pip install lca\n",
    "# %pip install banjo\n",
    "# %pip install tqdm\n",
    "# %pip install oauth2client\n",
    "# %pip install tqdm.contrib\n",
    "# %pip install google-generativeai\n",
    "# %pip install google-genai\n",
    "# %pip install av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cec3c6a3-1c9a-45a4-8703-cf68adf92dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger shibainu (ERROR)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import av\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.concurrent import thread_map\n",
    "from functools import partial\n",
    "\n",
    "from google.cloud import bigquery, storage\n",
    "from google import genai\n",
    "from google.api_core.exceptions import TooManyRequests\n",
    "\n",
    "from banjo import utils\n",
    "from banjo.utils.shibainu import (\n",
    "    Classification,\n",
    "    estimate_run_cost,\n",
    "    configure_logger,\n",
    ")\n",
    "\n",
    "# Import maps viral places classification utils\n",
    "from utils.constant import get_viral_places_query, place_agg_dict, PLACE_REQUIRED_KEYS, PLACE_LIST_COLS, VIDEO_REQUIRED_KEYS, SELECTED_COLS, STORY_COLS_RENAME\n",
    "from utils.helper import download_and_upload, topk_by_score_per_place, parse_incident_json_broken, parse_incident_safe, majority_vote, combine_text_list\n",
    "from utils.prompt import VIDEO_CLASSIFIER_PROMPT, TEXT_CLASSIFIER_PROMPT\n",
    "\n",
    "# Configure logging\n",
    "configure_logger(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa0a94",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "625d2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '20250703'\n",
    "END_DATE = '20250705'\n",
    "VIEW_WEIGHT = 0.6\n",
    "FRESHNESS_WEIGHT = 0.4\n",
    "SAMPLE_PER_PLACE = 5\n",
    "MAX_WORKERS = 10\n",
    "\n",
    "# Initialize GCS client\n",
    "client = storage.Client(project=\"myaigcp\")\n",
    "BUCKET_NAME = \"shiba-inu-temp\"\n",
    "BUCKET_FOLDER = \"maps_events_20250720\"\n",
    "BUCKET = client.bucket(BUCKET_NAME)\n",
    "\n",
    "# Save Destination \n",
    "WRITE_PROJECT_ID = \"sc-bq-gcs-billingonly\"\n",
    "WRITE_DATASET = \"temp_datascience\"\n",
    "WRITE_TABLE_NAME = \"maps_viral_places_classification\"\n",
    "\n",
    "DESTINATION = f\"{WRITE_PROJECT_ID}.{WRITE_DATASET}.{WRITE_TABLE_NAME}\"\n",
    "# SERVICE_ACCOUNT = 'shiba-inu@sc-product-datascience.iam.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8586e21",
   "metadata": {},
   "source": [
    "#### Import Data and Upload Media URL to GCS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "834a3cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1762276756.669660 35531534 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Import Data\n",
    "query = get_viral_places_query(START_DATE, END_DATE, VIEW_WEIGHT, FRESHNESS_WEIGHT)\n",
    "df = utils.gbq.read_gbq(query, \n",
    "                    project_id=\"myaigcp\",\n",
    "                    dialect=\"standard\",\n",
    "                    priority=\"interactive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Download and Upload Media URL to GCS\n",
    "worker = partial(\n",
    "    download_and_upload,\n",
    "    bucket=BUCKET,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    bucket_folder=BUCKET_FOLDER,\n",
    "    url_col='media_url',\n",
    "    id_col='story_snap_id',\n",
    ")\n",
    "rows = df.to_dict(orient=\"records\")       \n",
    "with ThreadPoolExecutor(max_workers=10) as ex:\n",
    "    results = list(tqdm(ex.map(worker, rows), total=len(rows)))\n",
    "\n",
    "# Write the results back to the original df\n",
    "df.loc[df.index, \"gcs_url\"] = results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f49f1",
   "metadata": {},
   "source": [
    "#### Call Shibainu Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69c6ab06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a large language model, trained by Google.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Initialize Shibainu Classification\n",
    "video_classifier = Classification(\n",
    "    provider_name=\"gemini\",\n",
    "    model_name='gemini-2.0-flash',\n",
    "    input_type=\"video\",\n",
    "    provider_config={\"project_id\": \"myaigcp\",\n",
    "                    \"location\": \"us-central1\"}, #this config is used for gemini only\n",
    "    processor_config = {\n",
    "        \"processing_mode\": \"image_url\",  # \"image_url\" or \"bytes\"\n",
    "        'return_direct_url': True       \n",
    "    },\n",
    "    model_parameters={\n",
    "        \"temperature\": 0,\n",
    "        \"max_token\": 1024\n",
    "    },\n",
    "    prompt=VIDEO_CLASSIFIER_PROMPT\n",
    ")\n",
    "\n",
    "video_classifier.get_result(video_classifier.send_message('What is your model?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82eb60d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:32<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step2: Choose top K videos per place and run classification\n",
    "df_selected_raw = topk_by_score_per_place(df, group_col='place_id', order_col='score', filter_col='gcs_url', k=SAMPLE_PER_PLACE)\n",
    "video_classifier_results = thread_map(video_classifier.classify, df_selected_raw['gcs_url'].tolist(), max_workers=MAX_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "790c56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Parse labels and construct the summary table\n",
    "video_labels = [video_classifier.get_result(r) for r in video_classifier_results]\n",
    "video_usage  = [video_classifier.get_token_usage(r) for r in video_classifier_results]\n",
    "\n",
    "df_video_summary = df_selected_raw.copy()\n",
    "df_video_summary.loc[:, \"video_labels\"] = video_labels\n",
    "df_video_summary.loc[:, \"video_prompt_tokens\"]= [u.get(\"prompt_tokens\") for u in video_usage]\n",
    "df_video_summary.loc[:, \"video_completion_tokens\"]= [u.get(\"completion_tokens\") for u in video_usage]\n",
    "\n",
    "# 3.1 Parse labels\n",
    "video_parsed = (\n",
    "    df_video_summary[\"video_labels\"]\n",
    "    .map(lambda x: parse_incident_safe(x, VIDEO_REQUIRED_KEYS))\n",
    "    .apply(pd.Series)\n",
    ")\n",
    "\n",
    "# 3.2 Attach parsed columns\n",
    "df_video_summary = pd.concat([df_video_summary, video_parsed], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173fc9a",
   "metadata": {},
   "source": [
    "#### Using Text Classification to Consolidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f253e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate\n",
    "df_place_raw = df_video_summary.groupby('place_id', as_index=False).agg(place_agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d21e353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:04<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Text classification\n",
    "text_classifier = Classification(\n",
    "    provider_name=\"gemini\",\n",
    "    model_name='gemini-2.0-flash',\n",
    "    input_type=\"text\",\n",
    "    provider_config={\"project_id\": \"myaigcp\",\n",
    "                    \"location\": \"us-central1\"}, #this config is used for gemini only\n",
    "    # processor_config = {\n",
    "    #     \"processing_mode\": \"image_url\",  # \"image_url\" or \"bytes\"\n",
    "    #     'return_direct_url': True       \n",
    "    # },\n",
    "    model_parameters={\n",
    "        \"temperature\": 0,\n",
    "        \"max_token\": 2000,\n",
    "    },\n",
    "    prompt=TEXT_CLASSIFIER_PROMPT\n",
    ")\n",
    "\n",
    "text_results = thread_map(text_classifier.classify, df_place_raw.to_dict(\"records\"), max_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a257553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the results\n",
    "text_labels = [text_classifier.get_result(r) for r in text_results]\n",
    "\n",
    "df_place_summary = df_place_raw.copy()\n",
    "df_place_summary.drop(columns=[\"key_objects_entities\", \"activity_type\", \"contributing_context\",\n",
    "                               \"short_description\", \"long_description\", \"keywords\"], inplace=True)\n",
    "df_place_summary.loc[:, \"text_labels\"] = text_labels\n",
    "\n",
    "\n",
    "# Parse labels\n",
    "text_parsed = (\n",
    "    df_place_summary[\"text_labels\"]\n",
    "    .map(lambda x: parse_incident_safe(x, PLACE_REQUIRED_KEYS))\n",
    "    .apply(pd.Series)\n",
    ")\n",
    "\n",
    "df_place_summary = pd.concat([df_place_summary, text_parsed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d62f21ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key_objects_entities',\n",
       " 'activity_type',\n",
       " 'short_description',\n",
       " 'long_description',\n",
       " 'keywords',\n",
       " 'consistency']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PLACE_REQUIRED_KEYS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa76890e",
   "metadata": {},
   "source": [
    "#### Consolidate the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd309b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_summary = df_video_summary.rename(\n",
    "    columns={col: f\"video_{col}\" for col in STORY_COLS_RENAME}\n",
    ")\n",
    "df_merged = df_place_summary.merge(df_video_summary, on=['place_id', 'continent','place_name', 'place_country_code',\n",
    "                                                        'detection_start_time', 'detection_end_time'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df518af",
   "metadata": {},
   "source": [
    "#### Write Output to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52340377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 6574.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`sc-bq-gcs-billingonly.temp_datascience.maps_viral_places_classification` was created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged.to_gbq(destination_table= DESTINATION, project_id= WRITE_PROJECT_ID, if_exists='replace')\n",
    "print(f\"`{DESTINATION}` was created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
